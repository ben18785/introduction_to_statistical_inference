{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing determinants of wine price using wine review data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are going to use a subset of a large [dataset of wine reviews](https://www.kaggle.com/zynicide/wine-reviews) to examine the relationship between critic-ascribed quality (\"points\") and the price of wines.\n",
    "\n",
    "The analysis is going to be carried out using regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Pandas, import the data into a dataframe and examine the first few rows of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot critic score (\"points\") versus price. To do this, use Matplotlib.pyplot's scatter function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are first going to assume a linear regression model of the form:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{price}_i = a + b *\\text{points}_i + \\epsilon_i\n",
    "\\end{equation}\n",
    "\n",
    "where $\\epsilon_i$ represents an error term and $a$ and $b$ are parameters to estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the least squares estimates of parameters using Sklearn via the following code:\n",
    "\n",
    "`from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "X = df[\"points\"]\n",
    "y = df[\"price\"]\n",
    "X = X.iloc[:, ].values.reshape(-1, 1)\n",
    "y = y.iloc[:, ].values.reshape(-1, 1)\n",
    "reg.fit(X, y)\n",
    "a = reg.intercept_[0]\n",
    "b = reg.coef_[0, 0]`\n",
    "\n",
    "Run this code to obtain estimates of the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does your model suggest is the average associated increase in wine price for a 1 unit change in points?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot your estimated model regression line on top of the data. To do this use the following steps:\n",
    "\n",
    "1. Create a vector of grid point values between 80 and 100 using numpy's linspace.\n",
    "2. Calculate predicted prices for each point value using your estimates of $a$ and $b$\n",
    "3. Reuse your scatter plot code from above and run `plt.plot(points, price)` after your previous `plt.scatter(..)` command to overlay the regression line on top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Â Deriving least squares estimates from first principles\n",
    "This section is optional as it is more mathematically involved. If you don't feel like doing this maths, you can skip ahead to the next section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are first going to estimate these parameters using the \"least-squares\" method. This method selects values for $(a,b)$ by minimising the sum of square errors (SSE) between model predictions and observations:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{SSE} = \\sum_{i=1}^{n} (\\text{price}_i - (a + b *\\text{points}_i))^2\n",
    "\\end{equation}\n",
    "\n",
    "Write a function which takes a single two-element vector argument (\"params\", with \"params[0]=a\" and \"params[1]=b\") as an argument and returns the SSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to use Scipy's optimiser to find the parameters which minimise the SSE. To do so use:\n",
    "\n",
    "`import scipy.optimize as optimize`\n",
    "\n",
    "then use the `optimize.minimize` function to find them. Note, one of the function arguments is an initial guess of the parameter values. For this choose: $a=-400$ and $b=4$. Note also that the estimates are given as a dictionary and the \"x\" key corresponds to the parameter values.\n",
    "\n",
    "Confirm that these estimates are the same as were obtained via the sklearn approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to use the sum of absolute errors (SAE) as our distance function and use it to determine new estimates:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{SAE} = \\sum_{i=1}^{n} |\\text{price}_i - (a + b *\\text{points}_i)|\n",
    "\\end{equation}\n",
    "\n",
    "Write a function which returns the SAE. Then use it as an input to Scipy's optimiser to find the new parameter estimates. Compare the regression line from these estimates with the least-squares line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the estimates of the $b$ parameter from the least-squares and absolute deviation loss functions. Why are they different?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the model's assumptions\n",
    "\n",
    "In this section, we are going to run some diagnostic checks on our regression model. The first of these is going to check the linearity assumption.\n",
    "\n",
    "To do this, you will need to extract the residuals from the model. These are defined as the difference between the model predictions and the actual values:\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{residual}_i = \\text{price}_i - (a + b * \\text{points}_i)\n",
    "\\end{equation}\n",
    "\n",
    "where $a$ and $b$ are the estimated parameters.\n",
    "\n",
    "First, calculate the residuals for the least-squares regression model. Then make a scatter plot of the residuals versus points. What does the plot indicate about this assumption?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our next diagnostic, we are going to check the assumption of the homogeneity of residual variance. To do this, we calculate the squared residuals then plot these versus the points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you conclude about the validity of the assumptions behind the linear regression model from your previous checks?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative model takes the logarithm of both the points and the price and assumptions a linear relationship between these:\n",
    "\n",
    "\\begin{equation}\n",
    "\\log\\text{price}_i = a + b * \\log\\text{points}_i + \\epsilon_i\n",
    "\\end{equation}\n",
    "\n",
    "By adapting the sklearn code from above, estimate this regression model and plot your fitted regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform the same diagnostic checks on this new model as we previously performed. How does this model perform?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further regression interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the parameter estimates from fitting the log-log model, determine which countries tend to have wine that is the best and worst value. (Note, remove the first 100 countries from the analysis to avoid outliers.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uncertainty through bootstrapping\n",
    "\n",
    "In this next section of the problems, we are going to determine an estimate of uncertainty in our least squares estimates of the log-log model:\n",
    "\n",
    "\\begin{equation}\n",
    "\\log\\text{price}_i = a + b * \\log\\text{points}_i + \\epsilon_i.\n",
    "\\end{equation}\n",
    "\n",
    "To do this, we are going to use boostrap sampling. In this, we randomly sample the rows of our dataset, with replacement, and re-estimate the regression model on each of these samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function which draws a new bootstrap sample and uses the sklearn functionality to fit a least-squares regression to that dataset. Your function should return estimates of both $a$ and $b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use your function to obtain 3 bootstrap estimates of the parameters. Plot the regression lines for these three cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now perform 1000 bootstrapped estimates and plot the distribution of $b$ estimates as a histogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are your 95% uncertainty bounds on the parameter using these boostrapped estimates? Hint: use numpy's quantile function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Causality and regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do the preceding analyses suggest is the effect of increasing wine quality (as measured by points) on the price that it sells for?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this situation, what sort of data would be need to collect to determine how wine quality affects its price?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
